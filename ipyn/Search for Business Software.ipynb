{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cat_name(cat_name): \n",
    "    cat_name = re.sub('\\s','_', cat_name)\n",
    "    return cat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cat_name(cat_name): \n",
    "    cat_name = re.sub('\\s','_', cat_name)\n",
    "    return cat_name\n",
    "def get_content_df(cat_name):\n",
    "    params = {'action':'query',\n",
    "          'titles':format_cat_name(cat_name),\n",
    "          'prop':'extracts',\n",
    "          'rvprop': 'content',\n",
    "          'format':'json'}\n",
    "    \n",
    "    response = requests.get('http://en.wikipedia.org/w/api.php?', params=params)\n",
    "    data = response.json()\n",
    "    return_data = data['query']['pages']\n",
    "    \n",
    "    page_id = list(return_data.keys())[0]\n",
    "    content = return_data[page_id]['extract']\n",
    "    soup = BeautifulSoup(content,\"html5lib\")\n",
    "    \n",
    "    temp_str=str()\n",
    "    for string in soup.stripped_strings:\n",
    "        temp_str += string \n",
    "    \n",
    "    \n",
    "    #clean = str(temp_list)\n",
    "    \n",
    "    title = format_cat_name(cat_name)\n",
    "    \n",
    "    content_df = pd.DataFrame([page_id, title, temp_str],index=(['page_id', 'title', 'content'])).T\n",
    "    \n",
    "    \n",
    "    return content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_content_df = pd.read_pickle(\"bs_content_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44674463</td>\n",
       "      <td>RamBase</td>\n",
       "      <td>RamBaseis a Norwegian fully integrated cloud E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34291637</td>\n",
       "      <td>XCOM:_Enemy_Unknown</td>\n",
       "      <td>XCOM: Enemy Unknownis a turn-based tactical vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26762608</td>\n",
       "      <td>Scientific_workflow_system</td>\n",
       "      <td>Ascientific workflow systemis a specialized fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327999</td>\n",
       "      <td>SASI_(software)</td>\n",
       "      <td>SASI (Schools Administrative Student Informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20217224</td>\n",
       "      <td>Tropico_3</td>\n",
       "      <td>Tropico 3is a video game developed by Haemimon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_id                       title  \\\n",
       "0  44674463                     RamBase   \n",
       "0  34291637         XCOM:_Enemy_Unknown   \n",
       "0  26762608  Scientific_workflow_system   \n",
       "0    327999             SASI_(software)   \n",
       "0  20217224                   Tropico_3   \n",
       "\n",
       "                                             content  \n",
       "0  RamBaseis a Norwegian fully integrated cloud E...  \n",
       "0  XCOM: Enemy Unknownis a turn-based tactical vi...  \n",
       "0  Ascientific workflow systemis a specialized fo...  \n",
       "0  SASI (Schools Administrative Student Informati...  \n",
       "0  Tropico 3is a video game developed by Haemimon...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_content_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare TFIDF Term Frequency * inverse Document Frequency\n",
    "\n",
    "bs_tfidf_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english')\n",
    "\n",
    "bs_tfidf_term_matrix_sps = bs_tfidf_vectorizer.fit_transform(bs_content_df.content)\n",
    "\n",
    "bs_tfidf_term_matrix_df = pd.DataFrame(bs_tfidf_term_matrix_sps.toarray(),\n",
    "                                       index=bs_content_df.content,\n",
    "                                       columns=bs_tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     AlphaGo versus Lee Sedol, orGoogle DeepMind Ch...\n",
       "1      AlphaGo won all but the fourth game; all game...\n",
       "2      The match has been compared with the historic...\n",
       "3     The winner of the match was slated to win $1 m...\n",
       "4      Since AlphaGo won, Google DeepMind stated tha...\n",
       "5      Lee received $170,000 ($150,000 for participa...\n",
       "6     After the match, The Korea Baduk Association a...\n",
       "7      It was given in recognition of AlphaGo\\'s \"si...\n",
       "8      This match was chosen byScienceas one of the ...\n",
       "9     BackgroundDifficult challenge in artificial in...\n",
       "10     It has long been considered a difficult chall...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_go = get_content_df('AlphaGo versus Lee Sedol')\n",
    "\n",
    "alpha_go_str = str(alpha_go['content'].values).split('.')[:11]\n",
    "\n",
    "alpha_go_df = pd.DataFrame(data = [x for x in alpha_go_str])\n",
    "\n",
    "alpha_go_df[0][0]='AlphaGo versus Lee Sedol, orGoogle DeepMind Challenge Match, was a five-game Go match between 18-time world champion Lee Sedol and AlphaGo, a computer Go program developed by Google DeepMind, played in Seoul, South Korea between 9 and 15 March 2016'\n",
    "\n",
    "alpha_go_df.columns=['content']\n",
    "\n",
    "alpha_go_df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_go_df.to_pickle('alpha_go.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_go_df = pd.read_pickle('alpha_go.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english')\n",
    "\n",
    "ag_tfidf_term_matrix_sps = tfidf_vectorizer.fit_transform(alpha_go_df.content)\n",
    "\n",
    "ag_tfidf_term_matrix_df = pd.DataFrame(ag_tfidf_term_matrix_sps.toarray(),\n",
    "                                       index=alpha_go_df.content,\n",
    "                                       columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_random_search_df = ag_tfidf_term_matrix_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_with_search_term = bs_tfidf_term_matrix_df.append(ag_random_search_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "SVD = TruncatedSVD(n_components)\n",
    "bs_component_names = [\"component_\"+str(i+1) for i in range(n_components)]\n",
    "\n",
    "bs_svd_matrix = SVD.fit_transform(bs_with_search_term)\n",
    "\n",
    "bs_svd_df = pd.DataFrame(bs_svd_matrix, \n",
    "                      index=bs_with_search_term.index, \n",
    "                      columns=component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_search_term_svd_vector = bs_svd_df.loc[ag_random_search_df.index]\n",
    "bs_search_term_svd_vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "bs_svd_df['cosine_sim'] = cosine_similarity(bs_svd_df, bs_search_term_svd_vector)\n",
    "\n",
    "ml_svd_df[['cosine_sim']].sort_values('cosine_sim', ascending=False).head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
